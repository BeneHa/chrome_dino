{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-digit recognition of Chrome dinosaur score using the Keras functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "#from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = \"C:/Users/bened/OneDrive/Arbeit/Lernen/python_training/score_pics/\"\n",
    "train_dir = base_dir + \"train_pics/\"\n",
    "validation_dir = base_dir + \"validation_pics/\"\n",
    "test_dir = base_dir + \"test_pics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training images: 29\n",
      "total validation images: 13\n",
      "total test images: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"total training images:\", len(os.listdir(train_dir)))\n",
    "print(\"total validation images:\", len(os.listdir(validation_dir)))\n",
    "print(\"total test images:\", len(os.listdir(test_dir)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_folder = base_dir + \"train_pics\"\n",
    "valid_folder = base_dir + \"validation_pics\"\n",
    "test_folder = base_dir + \"test_pics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_names = [f for f in os.listdir(train_folder)]\n",
    "valid_names = [f for f in os.listdir(valid_folder)]\n",
    "test_names = [f for f in os.listdir(test_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 training files\n",
      "58 validation files\n",
      "44 test files\n"
     ]
    }
   ],
   "source": [
    "print(str(len(train_names)) + \" training files\")\n",
    "print(str(len(valid_names)) + \" validation files\")\n",
    "print(str(len(test_names)) + \" test files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(fold, names):\n",
    "    dataset = np.ndarray(shape=(len(names), 50, 160, 3), dtype = np.float32)\n",
    "    i = 0\n",
    "    for f in names:\n",
    "        img = load_img(base_dir + fold + \"/\" + f)\n",
    "        x = img_to_array(img)\n",
    "        #x = x.reshape(())\n",
    "        x = (x - 128) / 128\n",
    "        dataset[i] = x\n",
    "        i += 1\n",
    "    dataset = dataset[:,:,:,0]\n",
    "    dataset = np.expand_dims(dataset, axis = 3)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def create_labels(names):\n",
    "    labels = [np.zeros((len(names),10)) for i in range(5)]\n",
    "    i = 0\n",
    "    for n in range(len(names)):\n",
    "        seq = names[n][0:5]\n",
    "        for digit in range(len(seq)):\n",
    "            label = int(seq[digit])\n",
    "            #print(str(digit) + \";\" + str(label) + \";\" + str(n))\n",
    "            labels[digit][n][label] = 1\n",
    "        i += 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(\"train_pics\", train_names)\n",
    "validation_dataset = create_dataset(\"validation_pics\", valid_names)\n",
    "test_dataset = create_dataset(\"test_pics\", test_names)\n",
    "\n",
    "train_labels = create_labels(train_names)\n",
    "validation_labels = create_labels(valid_names)\n",
    "test_labels = create_labels(test_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 50, 160, 1)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "#Filters:\n",
    "f1, f2, f3 = 8,16,32\n",
    "patch_size = 5\n",
    "k_size = (3,3)\n",
    "p_size = (4,4)\n",
    "n_class = 10\n",
    "node = 10\n",
    "\n",
    "inp_corr = Input(shape=(50,160,1))\n",
    "\n",
    "conv1 = Conv2D(filters = f1, kernel_size = k_size, activation = \"relu\")(inp_corr)\n",
    "#maxp1 = MaxPool2D(pool_size = p_size)(conv1)\n",
    "\n",
    "#conv2 = Conv2D(filters = f2, kernel_size = k_size, activation = \"relu\")(maxp1)\n",
    "#maxp2 = MaxPool2D(pool_size = p_size)(conv2)\n",
    "\n",
    "#conv3 = Conv2D(filters = f3, kernel_size = k_size, activation = \"relu\")(maxp2)\n",
    "#maxp3 = MaxPool2D(pool_size = p_size)(conv3)\n",
    "\n",
    "flat = Flatten()(conv1)\n",
    "#drop = Dropout(0.1)(flat)\n",
    "\n",
    "#dense_11 = Dense(node, activation = \"relu\")(drop)\n",
    "#dense_12 = Dense(node, activation = \"relu\")(drop)\n",
    "#dense_13 = Dense(node, activation = \"relu\")(drop)\n",
    "#dense_14 = Dense(node, activation = \"relu\")(drop)\n",
    "#dense_15 = Dense(node, activation = \"relu\")(drop)\n",
    "\n",
    "#dense_21 = Dense(n_class, activation = \"softmax\")(dense_11)\n",
    "#dense_22 = Dense(n_class, activation = \"softmax\")(dense_12)\n",
    "#dense_23 = Dense(n_class, activation = \"softmax\")(dense_13)\n",
    "#dense_24 = Dense(n_class, activation = \"softmax\")(dense_14)\n",
    "#dense_25 = Dense(n_class, activation = \"softmax\")(dense_15)\n",
    "\n",
    "#Alternative:\n",
    "dense_21 = Dense(n_class, activation = \"softmax\")(flat)\n",
    "dense_22 = Dense(n_class, activation = \"softmax\")(flat)\n",
    "dense_23 = Dense(n_class, activation = \"softmax\")(flat)\n",
    "dense_24 = Dense(n_class, activation = \"softmax\")(flat)\n",
    "dense_25 = Dense(n_class, activation = \"softmax\")(flat)\n",
    "\n",
    "output = [dense_21, dense_22, dense_23, dense_24, dense_25]\n",
    "\n",
    "#output = [dense_11, dense_12, dense_13, dense_14, dense_15]\n",
    "\n",
    "\n",
    "model = Model(input = inp_corr, output = output)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"sgd\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_44 (InputLayer)           (None, 50, 160, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 48, 158, 8)   80          input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 60672)        0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_216 (Dense)               (None, 10)           606730      flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_217 (Dense)               (None, 10)           606730      flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_218 (Dense)               (None, 10)           606730      flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_219 (Dense)               (None, 10)           606730      flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_220 (Dense)               (None, 10)           606730      flatten_25[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,033,730\n",
      "Trainable params: 3,033,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "132/132 [==============================] - 4s 32ms/step - loss: 9.5388 - dense_216_loss: 0.8305 - dense_217_loss: 1.0131 - dense_218_loss: 2.4760 - dense_219_loss: 2.5887 - dense_220_loss: 2.6305 - dense_216_acc: 0.6288 - dense_217_acc: 0.6212 - dense_218_acc: 0.1288 - dense_219_acc: 0.1818 - dense_220_acc: 0.1212\n",
      "Epoch 2/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 7.1411 - dense_216_loss: 0.4044 - dense_217_loss: 0.3631 - dense_218_loss: 1.9936 - dense_219_loss: 2.2052 - dense_220_loss: 2.1749 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 0.3182 - dense_219_acc: 0.3333 - dense_220_acc: 0.3409\n",
      "Epoch 3/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.7437 - dense_216_loss: 0.0303 - dense_217_loss: 0.0285 - dense_218_loss: 1.6647 - dense_219_loss: 2.0104 - dense_220_loss: 2.0099 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 0.3939 - dense_219_acc: 0.3712 - dense_220_acc: 0.4545\n",
      "Epoch 4/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 5.0953 - dense_216_loss: 0.0049 - dense_217_loss: 0.0046 - dense_218_loss: 1.4244 - dense_219_loss: 1.7977 - dense_220_loss: 1.8638 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 0.5455 - dense_219_acc: 0.7273 - dense_220_acc: 0.5227\n",
      "Epoch 5/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 4.4749 - dense_216_loss: 9.8598e-04 - dense_217_loss: 9.3291e-04 - dense_218_loss: 1.1725 - dense_219_loss: 1.6046 - dense_220_loss: 1.6959 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 0.7045 - dense_219_acc: 0.7652 - dense_220_acc: 0.7348\n",
      "Epoch 6/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.8509 - dense_216_loss: 3.8396e-04 - dense_217_loss: 3.6080e-04 - dense_218_loss: 0.9658 - dense_219_loss: 1.4044 - dense_220_loss: 1.4800 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 0.8864 - dense_219_acc: 0.7576 - dense_220_acc: 0.7879\n",
      "Epoch 7/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 3.1811 - dense_216_loss: 1.0320e-04 - dense_217_loss: 9.8427e-05 - dense_218_loss: 0.7456 - dense_219_loss: 1.1787 - dense_220_loss: 1.2566 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 0.9545 - dense_219_acc: 0.8106 - dense_220_acc: 0.8561\n",
      "Epoch 8/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 2.5802 - dense_216_loss: 2.4532e-05 - dense_217_loss: 2.3628e-05 - dense_218_loss: 0.5693 - dense_219_loss: 0.9743 - dense_220_loss: 1.0365 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 0.9621 - dense_219_acc: 0.9848 - dense_220_acc: 0.9015\n",
      "Epoch 9/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 2.2258 - dense_216_loss: 1.4904e-05 - dense_217_loss: 1.4359e-05 - dense_218_loss: 0.4476 - dense_219_loss: 0.8589 - dense_220_loss: 0.9193 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 0.8333 - dense_220_acc: 0.9318\n",
      "Epoch 10/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 1.6859 - dense_216_loss: 8.2399e-06 - dense_217_loss: 8.0435e-06 - dense_218_loss: 0.3410 - dense_219_loss: 0.6451 - dense_220_loss: 0.6998 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 0.9773 - dense_219_acc: 0.9848 - dense_220_acc: 0.9924\n",
      "Epoch 11/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 1.3557 - dense_216_loss: 2.6691e-06 - dense_217_loss: 2.5761e-06 - dense_218_loss: 0.2873 - dense_219_loss: 0.4837 - dense_220_loss: 0.5846 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 0.9924 - dense_220_acc: 0.9318\n",
      "Epoch 12/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.9802 - dense_216_loss: 7.4190e-07 - dense_217_loss: 7.2745e-07 - dense_218_loss: 0.2157 - dense_219_loss: 0.3662 - dense_220_loss: 0.3984 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 0.9924 - dense_220_acc: 0.9924\n",
      "Epoch 13/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.8135 - dense_216_loss: 2.7409e-07 - dense_217_loss: 2.8583e-07 - dense_218_loss: 0.1562 - dense_219_loss: 0.2923 - dense_220_loss: 0.3650 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 0.9924 - dense_220_acc: 0.9924\n",
      "Epoch 14/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.6593 - dense_216_loss: 1.6256e-07 - dense_217_loss: 1.6572e-07 - dense_218_loss: 0.1272 - dense_219_loss: 0.2383 - dense_220_loss: 0.2937 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 0.9924 - dense_220_acc: 0.9924\n",
      "Epoch 15/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.5379 - dense_216_loss: 1.2011e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.1053 - dense_219_loss: 0.2058 - dense_220_loss: 0.2268 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 0.9924 - dense_220_acc: 0.9924\n",
      "Epoch 16/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.4393 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0844 - dense_219_loss: 0.1648 - dense_220_loss: 0.1901 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 0.9924 - dense_220_acc: 0.9924\n",
      "Epoch 17/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.3882 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0725 - dense_219_loss: 0.1418 - dense_220_loss: 0.1739 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 0.9924 - dense_220_acc: 0.9924\n",
      "Epoch 18/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.3423 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0637 - dense_219_loss: 0.1269 - dense_220_loss: 0.1517 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 0.9924 - dense_220_acc: 0.9924\n",
      "Epoch 19/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2973 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0563 - dense_219_loss: 0.1072 - dense_220_loss: 0.1339 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 0.9924 - dense_220_acc: 0.9924\n",
      "Epoch 20/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2633 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0493 - dense_219_loss: 0.0935 - dense_220_loss: 0.1205 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 21/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2404 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0438 - dense_219_loss: 0.0854 - dense_220_loss: 0.1112 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 22/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2157 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0404 - dense_219_loss: 0.0767 - dense_220_loss: 0.0986 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 23/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1974 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0366 - dense_219_loss: 0.0673 - dense_220_loss: 0.0936 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 24/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1833 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0332 - dense_219_loss: 0.0617 - dense_220_loss: 0.0884 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1675 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0305 - dense_219_loss: 0.0560 - dense_220_loss: 0.0810 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 26/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1580 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0283 - dense_219_loss: 0.0516 - dense_220_loss: 0.0781 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 27/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1423 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0265 - dense_219_loss: 0.0475 - dense_220_loss: 0.0684 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 28/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1325 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0245 - dense_219_loss: 0.0442 - dense_220_loss: 0.0639 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 29/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1220 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0227 - dense_219_loss: 0.0408 - dense_220_loss: 0.0585 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 1.0000\n",
      "Epoch 30/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1186 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0215 - dense_219_loss: 0.0384 - dense_220_loss: 0.0587 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 31/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1107 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0203 - dense_219_loss: 0.0363 - dense_220_loss: 0.0542 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 32/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1065 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0191 - dense_219_loss: 0.0343 - dense_220_loss: 0.0531 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 33/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0997 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0182 - dense_219_loss: 0.0318 - dense_220_loss: 0.0496 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 34/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0996 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0172 - dense_219_loss: 0.0301 - dense_220_loss: 0.0524 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 35/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0932 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0163 - dense_219_loss: 0.0284 - dense_220_loss: 0.0485 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 1.0000\n",
      "Epoch 36/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0926 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0155 - dense_219_loss: 0.0272 - dense_220_loss: 0.0499 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 37/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0832 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0148 - dense_219_loss: 0.0258 - dense_220_loss: 0.0426 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 38/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0764 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0142 - dense_219_loss: 0.0245 - dense_220_loss: 0.0377 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 39/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0758 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0136 - dense_219_loss: 0.0236 - dense_220_loss: 0.0386 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n",
      "Epoch 40/40\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0742 - dense_216_loss: 1.1921e-07 - dense_217_loss: 1.1921e-07 - dense_218_loss: 0.0130 - dense_219_loss: 0.0226 - dense_220_loss: 0.0386 - dense_216_acc: 1.0000 - dense_217_acc: 1.0000 - dense_218_acc: 1.0000 - dense_219_acc: 1.0000 - dense_220_acc: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f929ec8828>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, train_labels,nb_epoch = 40, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result(result):\n",
    "    resultstr = ''\n",
    "    for i in range(5):\n",
    "        resultstr += str(np.argmax(result[i]))\n",
    "    return resultstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction   Original file name  Correct\n",
      "\n",
      "\n",
      "00003          00003.png      True\n",
      "00004          00004.png      True\n",
      "00012          00012.png      True\n",
      "00013          00013.png      True\n",
      "00014          00014.png      True\n",
      "00020          00020.png      True\n",
      "00022          00022.png      True\n",
      "00023          00023.png      True\n",
      "00030          00030.png      True\n",
      "00031          00031.png      True\n",
      "00032          00032.png      True\n",
      "00039          00039.png      True\n",
      "00041          00041.png      True\n",
      "00042          00042.png      True\n",
      "00043          00043.png      True\n",
      "00046          00046.png      True\n",
      "00049          00049.png      True\n",
      "00050          00050.png      True\n",
      "00052          00052.png      True\n",
      "00059          00059.png      True\n",
      "00060          00060.png      True\n",
      "00061          00061.png      True\n",
      "00068          00068.png      True\n",
      "00070          00070.png      True\n",
      "00071          00071.png      True\n",
      "00078          00078.png      True\n",
      "00080          00080.png      True\n",
      "00081          00081.png      True\n",
      "00088          00088.png      True\n",
      "00090          00090.png      True\n",
      "00091          00091.png      True\n",
      "00098          00098.png      True\n",
      "00100          00100.png      True\n",
      "00231          00231.png      True\n",
      "00242          00242.png      True\n",
      "00265          00265.png      True\n",
      "00276          00276.png      True\n",
      "00288          00288.png      True\n",
      "00336          00336.png      True\n",
      "00360          00360.png      True\n",
      "00385          00385.png      True\n",
      "00400          00400.png      True\n",
      "00474          00474.png      True\n",
      "00600          12345.png      False\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "print(\"Prediction   Original file name  Correct\\n\\n\")\n",
    "for i in range(44):\n",
    "    y_pred = model.predict(test_dataset[i].reshape(1, 50, 160, 1))\n",
    "    real = test_names[i][0:5]\n",
    "    comp = (real == get_result(y_pred))\n",
    "    print(get_result(y_pred) + \"          \" + str(test_names[i]) + \"      \" + str(comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00003'"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAEUCAYAAACMHEjfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nagB10CMPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f9321ff588>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 138,
       "width": 370
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(test_dataset[0,:,:,0], cmap = \"gray\")\n",
    "get_result(model.predict(test_dataset[0].reshape(1, 50, 160, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "Overfitting?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
