{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import *\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from score_dataset_helpers import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = 'C:/Users/bened/OneDrive/Arbeit/Lernen/python_training/data_dual_inputs/'\n",
    "train_dir = base_dir + 'train'\n",
    "validation_dir = base_dir + 'validation'\n",
    "test_dir = base_dir + 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1, f2, f3 = 8,16,32\n",
    "k_size = (3,3)\n",
    "\n",
    "pics_input = Input(shape = (75, 250, 3))\n",
    "pics_c1 = Conv2D(filters = f1, kernel_size = k_size, activation = \"relu\")(pics_input)\n",
    "pics_m1 = MaxPooling2D(k_size)(pics_c1)\n",
    "pics_c2 = Conv2D(filters = f2, kernel_size = k_size, activation = \"relu\")(pics_m1)\n",
    "pics_m2 = MaxPooling2D(k_size)(pics_c2)\n",
    "#pics_c3 = Conv2D(filters = f3, kernel_size = k_size, activation = \"relu\")(pics_m2)\n",
    "#pics_m3 = MaxPooling2D((2,2))(pics_c3)\n",
    "pics_f = Flatten()(pics_m2)\n",
    "pics_d = Dense(20, activation = \"relu\")(pics_f)\n",
    "\n",
    "nums_input = Input(shape = ([1]))\n",
    "nums_features = Dense(5, activation = \"relu\")(nums_input)\n",
    "\n",
    "conc_layer = concatenate([pics_d, nums_features])\n",
    "dense_1 = Dense(100, activation = \"relu\")(conc_layer)\n",
    "#dense_12 = Dense(100, activation = \"softmax\")(dense_1)\n",
    "dense_2 = Dense(1, activation = \"sigmoid\")(dense_1)\n",
    "\n",
    "model = Model(inputs = [pics_input, nums_input], outputs = dense_2)\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 75, 250, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 73, 248, 8)   224         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 24, 82, 8)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 22, 80, 16)   1168        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 26, 16)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2912)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20)           58260       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            10          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 25)           0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          2600        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            101         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 62,363\n",
      "Trainable params: 62,363\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vectors of scores from pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scores = train_dir + \"/score\"\n",
    "train_pics = train_dir + \"/pics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_names_scores = [f for f in os.listdir(train_scores)]\n",
    "train_names_pics = [f for f in os.listdir(train_pics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517 training files for scores\n",
      "517 training files for pictures\n"
     ]
    }
   ],
   "source": [
    "print(str(len(train_names_scores)) + \" training files for scores\")\n",
    "print(str(len(train_names_pics)) + \" training files for pictures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset_score = create_dataset(\"score\", train_names_scores, base_dir + \"train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result(result):\n",
    "    resultstr = ''\n",
    "    for i in range(5):\n",
    "        resultstr += str(np.argmax(result[i]))\n",
    "    return resultstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_model = load_model(\"C:/Users/bened/OneDrive/Arbeit/Lernen/python_training/models/score_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create vectors for scores and for labels\n",
    "score_vec = []\n",
    "for i in range(len(train_names_scores)):\n",
    "    y_pred = score_model.predict(train_dataset_score[i].reshape(1, 50, 160, 1))\n",
    "    score_vec.append(get_result(y_pred))\n",
    "\n",
    "label_vec = ['up' in x for x in train_names_pics]\n",
    "label_vec = np.array(label_vec)\n",
    "label_array = label_vec.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>orig_name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_1.png</td>\n",
       "      <td>00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_10.png</td>\n",
       "      <td>00073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_100.png</td>\n",
       "      <td>00172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_101.png</td>\n",
       "      <td>00185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_102.png</td>\n",
       "      <td>00190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_105.png</td>\n",
       "      <td>00200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_106.png</td>\n",
       "      <td>00200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_107.png</td>\n",
       "      <td>00226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_108.png</td>\n",
       "      <td>00238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_109.png</td>\n",
       "      <td>00243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_11.png</td>\n",
       "      <td>00089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_110.png</td>\n",
       "      <td>00254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_111.png</td>\n",
       "      <td>00261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_112.png</td>\n",
       "      <td>00271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_113.png</td>\n",
       "      <td>00277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_114.png</td>\n",
       "      <td>00289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_115.png</td>\n",
       "      <td>00295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_118.png</td>\n",
       "      <td>00300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_119.png</td>\n",
       "      <td>00334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_12.png</td>\n",
       "      <td>00098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_120.png</td>\n",
       "      <td>00340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_121.png</td>\n",
       "      <td>00352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_122.png</td>\n",
       "      <td>00358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_123.png</td>\n",
       "      <td>00368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_124.png</td>\n",
       "      <td>00373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_125.png</td>\n",
       "      <td>00383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_126.png</td>\n",
       "      <td>00396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_130.png</td>\n",
       "      <td>00429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_131.png</td>\n",
       "      <td>00439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>right_132.png</td>\n",
       "      <td>00445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_6.png</td>\n",
       "      <td>00084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_60.png</td>\n",
       "      <td>00194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_61.png</td>\n",
       "      <td>00199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_63.png</td>\n",
       "      <td>00231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_64.png</td>\n",
       "      <td>00248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_65.png</td>\n",
       "      <td>00265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_66.png</td>\n",
       "      <td>00283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_68.png</td>\n",
       "      <td>00300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_69.png</td>\n",
       "      <td>00326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_7.png</td>\n",
       "      <td>00093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_70.png</td>\n",
       "      <td>00344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_71.png</td>\n",
       "      <td>00361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_72.png</td>\n",
       "      <td>00376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_73.png</td>\n",
       "      <td>00389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_75.png</td>\n",
       "      <td>00400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_76.png</td>\n",
       "      <td>00433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_77.png</td>\n",
       "      <td>00450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_78.png</td>\n",
       "      <td>00467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_79.png</td>\n",
       "      <td>00483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_82.png</td>\n",
       "      <td>00500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_83.png</td>\n",
       "      <td>00528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_84.png</td>\n",
       "      <td>00544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_85.png</td>\n",
       "      <td>00560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_86.png</td>\n",
       "      <td>00577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_87.png</td>\n",
       "      <td>00594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_9.png</td>\n",
       "      <td>00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_90.png</td>\n",
       "      <td>00635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_91.png</td>\n",
       "      <td>00645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_92.png</td>\n",
       "      <td>00653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>1.0</td>\n",
       "      <td>up_93.png</td>\n",
       "      <td>00669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label      orig_name  score\n",
       "0      0.0    right_1.png  00008\n",
       "1      0.0   right_10.png  00073\n",
       "2      0.0  right_100.png  00172\n",
       "3      0.0  right_101.png  00185\n",
       "4      0.0  right_102.png  00190\n",
       "5      0.0  right_105.png  00200\n",
       "6      0.0  right_106.png  00200\n",
       "7      0.0  right_107.png  00226\n",
       "8      0.0  right_108.png  00238\n",
       "9      0.0  right_109.png  00243\n",
       "10     0.0   right_11.png  00089\n",
       "11     0.0  right_110.png  00254\n",
       "12     0.0  right_111.png  00261\n",
       "13     0.0  right_112.png  00271\n",
       "14     0.0  right_113.png  00277\n",
       "15     0.0  right_114.png  00289\n",
       "16     0.0  right_115.png  00295\n",
       "17     0.0  right_118.png  00300\n",
       "18     0.0  right_119.png  00334\n",
       "19     0.0   right_12.png  00098\n",
       "20     0.0  right_120.png  00340\n",
       "21     0.0  right_121.png  00352\n",
       "22     0.0  right_122.png  00358\n",
       "23     0.0  right_123.png  00368\n",
       "24     0.0  right_124.png  00373\n",
       "25     0.0  right_125.png  00383\n",
       "26     0.0  right_126.png  00396\n",
       "27     0.0  right_130.png  00429\n",
       "28     0.0  right_131.png  00439\n",
       "29     0.0  right_132.png  00445\n",
       "..     ...            ...    ...\n",
       "487    1.0       up_6.png  00084\n",
       "488    1.0      up_60.png  00194\n",
       "489    1.0      up_61.png  00199\n",
       "490    1.0      up_63.png  00231\n",
       "491    1.0      up_64.png  00248\n",
       "492    1.0      up_65.png  00265\n",
       "493    1.0      up_66.png  00283\n",
       "494    1.0      up_68.png  00300\n",
       "495    1.0      up_69.png  00326\n",
       "496    1.0       up_7.png  00093\n",
       "497    1.0      up_70.png  00344\n",
       "498    1.0      up_71.png  00361\n",
       "499    1.0      up_72.png  00376\n",
       "500    1.0      up_73.png  00389\n",
       "501    1.0      up_75.png  00400\n",
       "502    1.0      up_76.png  00433\n",
       "503    1.0      up_77.png  00450\n",
       "504    1.0      up_78.png  00467\n",
       "505    1.0      up_79.png  00483\n",
       "506    1.0      up_82.png  00500\n",
       "507    1.0      up_83.png  00528\n",
       "508    1.0      up_84.png  00544\n",
       "509    1.0      up_85.png  00560\n",
       "510    1.0      up_86.png  00577\n",
       "511    1.0      up_87.png  00594\n",
       "512    1.0       up_9.png  00100\n",
       "513    1.0      up_90.png  00635\n",
       "514    1.0      up_91.png  00645\n",
       "515    1.0      up_92.png  00653\n",
       "516    1.0      up_93.png  00669\n",
       "\n",
       "[517 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_dat = pd.DataFrame({'score' : score_vec, 'label' : label_array, 'orig_name' : train_names_scores})\n",
    "print_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pic_array = np.zeros((len(train_names_pics), 75, 250, 3))\n",
    "\n",
    "for i in range(len(train_names_pics)):\n",
    "    x = load_img(train_pics + '/' + train_names_pics[i], target_size = (75, 250))\n",
    "    #x = img_to_array(x)\n",
    "    pic_array[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [100., 100., 100.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [100., 100., 100.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 247., 247.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [ 83.,  83.,  83.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.],\n",
       "       [255., 255., 255.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_array[1][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pic_array = np.array(pic_array)\n",
    "pic_array /= 255\n",
    "score_array = np.array(score_vec)\n",
    "score_array = np.float32(score_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 75, 250, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 465 samples, validate on 52 samples\n",
      "Epoch 1/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.4416 - acc: 0.8237 - val_loss: 1.0897 - val_acc: 0.0769\n",
      "Epoch 2/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.3906 - acc: 0.8344 - val_loss: 0.8048 - val_acc: 0.5577\n",
      "Epoch 3/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.3286 - acc: 0.8710 - val_loss: 0.5194 - val_acc: 0.7692\n",
      "Epoch 4/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.2558 - acc: 0.9247 - val_loss: 0.3519 - val_acc: 0.8654\n",
      "Epoch 5/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.1980 - acc: 0.9398 - val_loss: 0.4067 - val_acc: 0.8077\n",
      "Epoch 6/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.1652 - acc: 0.9462 - val_loss: 0.5860 - val_acc: 0.7885\n",
      "Epoch 7/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.1469 - acc: 0.9505 - val_loss: 0.5282 - val_acc: 0.8077\n",
      "Epoch 8/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.1332 - acc: 0.9462 - val_loss: 0.2868 - val_acc: 0.8846\n",
      "Epoch 9/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.1206 - acc: 0.9591 - val_loss: 0.4118 - val_acc: 0.8654\n",
      "Epoch 10/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.1099 - acc: 0.9656 - val_loss: 0.4826 - val_acc: 0.8269\n",
      "Epoch 11/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.1069 - acc: 0.9484 - val_loss: 0.2227 - val_acc: 0.9231\n",
      "Epoch 12/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.1175 - acc: 0.9634 - val_loss: 0.5676 - val_acc: 0.8269\n",
      "Epoch 13/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.0978 - acc: 0.9570 - val_loss: 0.2951 - val_acc: 0.9038\n",
      "Epoch 14/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.0893 - acc: 0.9656 - val_loss: 0.3606 - val_acc: 0.8654\n",
      "Epoch 15/15\n",
      "465/465 [==============================] - 4s 8ms/step - loss: 0.0877 - acc: 0.9742 - val_loss: 0.3454 - val_acc: 0.8846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e76cda0b00>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([pic_array, score_array], label_array, epochs = 15, shuffle = True, batch_size = 100, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:/Users/bened/OneDrive/Arbeit/Lernen/python_training/models/model_dual_input.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (75, 250, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-fd2f156b1a7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpic_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              'argument.')\n\u001b[0;32m   1148\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (75, 250, 3)"
     ]
    }
   ],
   "source": [
    "model.predict([pic_array[1], score_array[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
